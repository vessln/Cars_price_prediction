%matplotlib inline


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score

import optuna
from optuna.visualization import plot_optimization_history

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error





data = pd.read_csv("data/analysed_data_07-03-2025.csv")
data.head()


data.describe().T











data = data.drop(columns = ['title'])


data.shape





features = data.drop(columns = ["price"]) # independent variables
target = data["price"]  


features.shape, target.shape





x_train, x_test, y_train, y_test = train_test_split(
    features,
    target, 
    test_size = 0.25, 
    random_state = 42)








num_features = ["mileage", "hp"]
cat_features = ["color", "fuel", "type", "region"]
passthrough_features = ["is_amg", "age"]





preprocessor1 = ColumnTransformer([
    ("num", Pipeline([("scaler", StandardScaler())]), num_features),
    ("cat", Pipeline([("encoder", OneHotEncoder(sparse_output = False, drop = None, handle_unknown = "ignore"))]), cat_features),
    ("passthrough", "passthrough", passthrough_features)
])


preprocessor1





class LabelEncoderTransformer(BaseEstimator, TransformerMixin):
    def fit(self, X, y = None):
        self.encoders = {}
        for col in X.columns:
            self.encoders[col] = LabelEncoder()
            self.encoders[col].fit(X[col])  # Fit only on training data
        return self

    def transform(self, X):
        X_encoded = X.copy()
        for col, encoder in self.encoders.items():
            X_encoded[col] = X[col].apply(lambda val: encoder.transform([val])[0] if val in encoder.classes_ else -1)
        return X_encoded


preprocessor2 = ColumnTransformer([
    ("num", Pipeline([("scaler", StandardScaler())]), num_features),
    ("cat", Pipeline([("encoder", LabelEncoderTransformer())]), cat_features),
    ("passthrough", "passthrough", passthrough_features)
])


preprocessor2














def objective(trial):
    # Choose which preprocessor to use: with OHE (preprocessor1) or with Label Encoder(preprocessor2):
    preprocessor_type = trial.suggest_categorical("preprocessor", ["OHE", "LE"])
    preprocessor = preprocessor1 if preprocessor_type == "OHE" else preprocessor2

    model_type = trial.suggest_categorical("regressor", ["LinearRegression", "DecisionTree", "RandomForest", "XGBoost"])

    if model_type == "LinearRegression":
        model = LinearRegression()
 
    elif model_type == "DecisionTree":
        model = DecisionTreeRegressor(
            max_depth = trial.suggest_int("max_depth", 2, 50),
            min_samples_split = trial.suggest_int("min_samples_split", 2, 10),
            min_samples_leaf = trial.suggest_int("min_samples_leaf", 1, 5),
            random_state = 42,
        )
    
    elif model_type == "RandomForest":
        model = RandomForestRegressor(
            n_estimators = trial.suggest_int("n_estimators", 50, 500),
            max_depth = trial.suggest_int("max_depth", 2, 30),
            min_samples_split = trial.suggest_int("min_samples_split", 2, 10),
            min_samples_leaf = trial.suggest_int("min_samples_leaf", 1, 5),
            random_state = 42,
        )

    elif model_type == "XGBoost":
        model = XGBRegressor(
            n_estimators = trial.suggest_int("n_estimators", 50, 500),
            max_depth = trial.suggest_int("max_depth", 2, 30),
            gamma = trial.suggest_float("gamma", 0, 5),
            learning_rate = trial.suggest_float("learning_rate", 1e-4, 1.0, log = True),
            subsample = trial.suggest_float("subsample", 0.5, 1.0),
            colsample_bytree = trial.suggest_float("colsample_bytree", 0.5, 1.0),
            random_state = 42,
        )

    pipeline = Pipeline([
        ("preprocessor", preprocessor),
        ("regressor", model),
    ])

    r2_score = cross_val_score(pipeline, x_train, y_train, cv = 5, scoring = "r2").mean()
    mse_score_mean = -cross_val_score(pipeline, x_train, y_train, cv = 5, scoring = "neg_mean_squared_error").mean()
    neg_mae_score_mean = -cross_val_score(pipeline, x_train, y_train, cv = 5, scoring = "neg_mean_absolute_error").mean()

    trial.set_user_attr("r2", r2_score)
    trial.set_user_attr("mse", mse_score_mean)
    trial.set_user_attr("preprocessor", preprocessor_type)

    return neg_mae_score_mean


study = optuna.create_study(study_name = "hyperparams_optimization", direction = "minimize")
study.optimize(objective, n_trials = 100)


print(f"Best parameters: {study.best_params}\nBest MAE score: {study.best_value}")


plot_optimization_history(study).show()


best_params = {}

for trial in study.trials:
    regressor = trial.params["regressor"]

    # i select the best models based on lowest MAE
    if regressor not in best_params or trial.value < best_params[regressor]["MAE_score"]:
        best_params[regressor] = {
            "params": trial.params, 
            "MAE_score": trial.value, 
            "MSE_score": trial.user_attrs["mse"],
            "R2_score": trial.user_attrs["r2"],
        }

for regressor, result in best_params.items():
    print(f"Best {regressor} model:\nhave parameters: {result['params']}")
    print(f"MAE: {result['MAE_score']:.2f}\nMSE: {result['MSE_score']:.2f}\nR²: {result['R2_score']:.4f}\n")








trained_models = {}

for regressor, result in best_params.items():
    preprocessor_type = result["params"]["preprocessor"]
    preprocessor = preprocessor1 if preprocessor_type == "OHE" else preprocessor2 
    best_model_params = result["params"]

    if regressor == "LinearRegression":
        best_model = LinearRegression()

    elif regressor == "DecisionTree":
        best_model = DecisionTreeRegressor(
            max_depth = best_model_params["max_depth"],
            min_samples_split = best_model_params["min_samples_split"],
            min_samples_leaf = best_model_params["min_samples_leaf"],
            random_state = 42,
        )

    elif regressor == "RandomForest":
        best_model = RandomForestRegressor(
            n_estimators = best_model_params["n_estimators"],
            max_depth = best_model_params["max_depth"],
            min_samples_split = best_model_params["min_samples_split"],
            min_samples_leaf = best_model_params["min_samples_leaf"],
            random_state = 42,
        )

    elif regressor == "XGBoost":
        best_model = XGBRegressor(
            n_estimators = best_model_params["n_estimators"],
            max_depth = best_model_params["max_depth"],
            learning_rate = best_model_params["learning_rate"],
            subsample = best_model_params["subsample"],
            colsample_bytree = best_model_params["colsample_bytree"],
            random_state = 42,
        )


    pipeline = Pipeline([
        ("preprocessor", preprocessor),
        ("regressor", best_model),
    ])

    # train the model:
    pipeline.fit(x_train, y_train)
    # store trained model:
    trained_models[regressor] = pipeline


# make and store predictions:
predictions = {}
for regressor, model in trained_models.items():
    y_pred = model.predict(x_test)
    predictions[regressor] = y_pred


predictions


evaluation_results = {}

for regressor, y_pred in predictions.items():
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    evaluation_results[regressor] = {"MAE": mae, "MSE": mse, "R²": r2}

    print(f"{regressor} model performance:")
    print(f"Test MAE: {mae:.2f}")
    print(f"Test MSE: {mse:.2f}")
    print(f"Test R²: {r2:.4f}\n")


best_models_test_results = pd.DataFrame.from_dict(evaluation_results, orient="index")
best_models_test_results














for regressor, y_pred in predictions.items():
    residuals = y_test - y_pred

    plt.figure(figsize = (6, 4))
    sns.scatterplot(x = y_pred, y = residuals, alpha = 0.8)
    plt.axhline(y = 0, color = "red", linestyle = "--")
    plt.xlabel("Predicted price")
    plt.ylabel("Residuals (actual - predicted)")
    plt.title(f"Residual Plot for {regressor}")
    plt.grid()
    plt.show()








for regressor, model in trained_models.items():
    if regressor in ["DecisionTree", "RandomForest", "XGBoost"]:
        feature_names = preprocessor.get_feature_names_out()
        importance = model.named_steps["regressor"].feature_importances_
        
        # sort feature importance:
        sorted_idx = np.argsort(importance)[::-1]
        sorted_features = np.array(feature_names)[sorted_idx]

        plt.figure(figsize = (8, 8))
        sns.barplot(x = importance[sorted_idx], y = sorted_features)
        plt.xlabel("Feature importance")
        plt.title(f"Feature Importance for {regressor}")
        plt.grid()
        plt.show()






